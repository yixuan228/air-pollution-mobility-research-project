{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5bf8542",
   "metadata": {},
   "source": [
    "# NO2 and economic activity model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9a1c3",
   "metadata": {},
   "source": [
    "## Addis-Ababa Random Forest + SHAP\n",
    "Here we load **all 730** daily meshes for Addis, build lag & neighbor features, train a global RF, and visualize SHAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf53fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# bring src/ into path\n",
    "CURR_PATH = Path().resolve()\n",
    "REPO_PATH = CURR_PATH.parent\n",
    "sys.path.append(str(REPO_PATH / \"src\"))\n",
    "\n",
    "# uppercase constants\n",
    "ADDIS_FOLDER = Path(\n",
    "    r\"C:\\Users\\Luis.ParraMorales\\AirPollution_Analysis\"\n",
    "    r\"\\air-pollution-mobility-research-project\\data\"\n",
    "    r\"\\Populated meshes\\addis-mesh-data\"\n",
    ")\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "\n",
    "# our feature-engineering helpers\n",
    "from feature_engineering import (\n",
    "    load_mesh_series, make_lag_features, NeighborAggregator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae0f85",
   "metadata": {},
   "source": [
    "### Load all daily meshes into one GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e519a1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 399126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geom_id</th>\n",
       "      <th>no2_mean</th>\n",
       "      <th>geometry</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>POLYGON ((38.78925 8.83942, 38.78925 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.79824 8.83942, 38.79824 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.80722 8.83942, 38.80722 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.8162 8.83942, 38.8162 8.84841, 38...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.82519 8.83942, 38.82519 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geom_id  no2_mean                                           geometry  \\\n",
       "0        0  0.000051  POLYGON ((38.78925 8.83942, 38.78925 8.84841, ...   \n",
       "1        1  0.000033  POLYGON ((38.79824 8.83942, 38.79824 8.84841, ...   \n",
       "2        2  0.000033  POLYGON ((38.80722 8.83942, 38.80722 8.84841, ...   \n",
       "3        3  0.000033  POLYGON ((38.8162 8.83942, 38.8162 8.84841, 38...   \n",
       "4        4  0.000033  POLYGON ((38.82519 8.83942, 38.82519 8.84841, ...   \n",
       "\n",
       "        date  \n",
       "0 2023-01-01  \n",
       "1 2023-01-01  \n",
       "2 2023-01-01  \n",
       "3 2023-01-01  \n",
       "4 2023-01-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = load_mesh_series(ADDIS_FOLDER)\n",
    "print(\"Total rows:\", len(gdf))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0c12f",
   "metadata": {},
   "source": [
    "### Create autoregressive lags 1…14 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ab0f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298158, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_lag_features(gdf, nlags=14)\n",
    "# drop the first 14 days per cell (NaN lags)\n",
    "df = df.dropna(subset=[f\"no2_mean_lag{l}\" for l in range(1,15)])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04f16c",
   "metadata": {},
   "source": [
    "### Precompute spatial neighbors and add mean-lag features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0bd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need one GeoDataFrame (static geometry & id)\n",
    "static = gdf.drop_duplicates([\"geom_id\"])[[\"geom_id\",\"geometry\"]].set_index(\"geom_id\")\n",
    "neighborer = NeighborAggregator(k=8, id_col=\"geom_id\")\n",
    "neighborer.fit(static.reset_index(), None)\n",
    "\n",
    "# apply to each row-group: transform expects the full static+lags DataFrame per time slice\n",
    "# so merge geometry into df and then extract neighbor features\n",
    "df_merged = (\n",
    "    df.merge(static.reset_index(), on=\"geom_id\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "neigh_feats = neighborer.transform(df_merged)\n",
    "# join back\n",
    "df_full = pd.concat([df_merged.reset_index(drop=True), neigh_feats], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7dc791",
   "metadata": {},
   "source": [
    "### Split into training (all 2023) vs test (last quarter 2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2930c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"year\"] = df_full[\"date\"].dt.year\n",
    "train = df_full[df_full[\"year\"] < 2024]\n",
    "test  = df_full[df_full[\"year\"] >= 2024]\n",
    "\n",
    "y_train = train[\"no2_mean\"]\n",
    "y_test  = test[\"no2_mean\"]\n",
    "cols_to_drop = [col for col in [\"no2_mean\", \"geometry\", \"date\", \"year\"] if col in train.columns]\n",
    "X_train = train.drop(columns=cols_to_drop)\n",
    "X_test  = test.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5287dd67",
   "metadata": {},
   "source": [
    "### Random Forest with scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea10377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where the target is missing\n",
    "train = train.dropna(subset=[\"no2_mean\"])\n",
    "test = test.dropna(subset=[\"no2_mean\"])\n",
    "\n",
    "y_train = train[\"no2_mean\"]\n",
    "y_test  = test[\"no2_mean\"]\n",
    "X_train = train.drop(columns=[\"no2_mean\", \"geometry\", \"geometry_x\", \"geometry_y\", \"date\", \"year\"], errors=\"ignore\")\n",
    "X_test  = test.drop(columns=[\"no2_mean\", \"geometry\", \"geometry_x\", \"geometry_y\", \"date\", \"year\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff994521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geom_id <class 'numpy.int64'>\n",
      "geometry_x <class 'shapely.geometry.polygon.Polygon'>\n",
      "no2_mean_lag1 <class 'numpy.float64'>\n",
      "no2_mean_lag2 <class 'numpy.float64'>\n",
      "no2_mean_lag3 <class 'numpy.float64'>\n",
      "no2_mean_lag4 <class 'numpy.float64'>\n",
      "no2_mean_lag5 <class 'numpy.float64'>\n",
      "no2_mean_lag6 <class 'numpy.float64'>\n",
      "no2_mean_lag7 <class 'numpy.float64'>\n",
      "no2_mean_lag8 <class 'numpy.float64'>\n",
      "no2_mean_lag9 <class 'numpy.float64'>\n",
      "no2_mean_lag10 <class 'numpy.float64'>\n",
      "no2_mean_lag11 <class 'numpy.float64'>\n",
      "no2_mean_lag12 <class 'numpy.float64'>\n",
      "no2_mean_lag13 <class 'numpy.float64'>\n",
      "no2_mean_lag14 <class 'numpy.float64'>\n",
      "geometry_y <class 'shapely.geometry.polygon.Polygon'>\n",
      "neigh_no2_mean_lag1 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag2 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag3 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag4 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag5 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag6 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag7 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag8 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag9 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag10 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag11 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag12 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag13 <class 'numpy.float64'>\n",
      "neigh_no2_mean_lag14 <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# See the actual column names and types\n",
    "for col in X_train.columns:\n",
    "    print(col, type(X_train.iloc[0][col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c98d1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB R²: 0.9293340411741373\n",
      "Test R²: 0.2123083860017977\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rf\", RandomForestRegressor(\n",
    "        n_estimators=300, \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        oob_score=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"OOB R²:\", pipeline.named_steps[\"rf\"].oob_score_)\n",
    "print(\"Test R²:\", pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99863934",
   "metadata": {},
   "source": [
    "### Global feature importance (mean |SHAP|) and beeswarm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(pipeline.named_steps[\"rf\"])\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# bar plot\n",
    "shap.plots.bar(explainer, max_display=15)\n",
    "# beeswarm\n",
    "shap.summary_plot(shap_values, X_test, max_display=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347e0aa",
   "metadata": {},
   "source": [
    "### Dependence plot for top-2 features, and mapping one SHAP feature back to space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = X_test.columns[np.argsort(np.abs(shap_values).mean(0))[-2:]]\n",
    "for feat in top_feats:\n",
    "    shap.dependence_plot(feat, shap_values, X_test)\n",
    "\n",
    "# map per-cell mean SHAP of first feature\n",
    "mean_shap = pd.DataFrame({\n",
    "    \"geom_id\": test[\"geom_id\"],\n",
    "    \"shap1\": shap_values[:, X_test.columns.get_loc(top_feats[-1])]\n",
    "}).groupby(\"geom_id\").mean().reset_index()\n",
    "\n",
    "map_gdf = static.reset_index().merge(mean_shap, on=\"geom_id\")\n",
    "map_gdf.plot(column=\"shap1\", legend=True, cmap=\"plasma\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e986807",
   "metadata": {},
   "source": [
    "### Approximate elasticities from SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticities = []\n",
    "for feat in X_test.columns:\n",
    "    dx = X_test[feat].quantile(0.75) - X_test[feat].quantile(0.25)\n",
    "    r = (shap_values[:, X_test.columns.get_loc(feat)] / pipeline.predict(X_test)) \\\n",
    "        * (X_test[feat] / dx)\n",
    "    elasticities.append({\n",
    "        \"feature\": feat,\n",
    "        \"median\": np.median(r),\n",
    "        \"p10\": np.percentile(r,10),\n",
    "        \"p90\": np.percentile(r,90)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(elasticities).sort_values(\"median\", ascending=False).head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
