{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5bf8542",
   "metadata": {},
   "source": [
    "# NO2 and economic activity model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9a1c3",
   "metadata": {},
   "source": [
    "## Addis-Ababa Random Forest + SHAP\n",
    "Here we load **all 730** daily meshes for Addis, build lag & neighbor features, train a global RF, and visualize SHAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf53fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# bring src/ into path\n",
    "CURR_PATH = Path().resolve()\n",
    "REPO_PATH = CURR_PATH.parent\n",
    "sys.path.append(str(REPO_PATH / \"src\"))\n",
    "\n",
    "# uppercase constants\n",
    "ADDIS_FOLDER = Path(\n",
    "    r\"C:\\Users\\Luis.ParraMorales\\AirPollution_Analysis\"\n",
    "    r\"\\air-pollution-mobility-research-project\\data\"\n",
    "    r\"\\Populated meshes\\addis-mesh-data\"\n",
    ")\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "\n",
    "# our feature-engineering helpers\n",
    "from feature_engineering import (\n",
    "    load_mesh_series, make_lag_features, NeighborAggregator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae0f85",
   "metadata": {},
   "source": [
    "### Load all daily meshes into one GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e519a1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 399126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geom_id</th>\n",
       "      <th>no2_mean</th>\n",
       "      <th>geometry</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>POLYGON ((38.78925 8.83942, 38.78925 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.79824 8.83942, 38.79824 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.80722 8.83942, 38.80722 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.8162 8.83942, 38.8162 8.84841, 38...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>POLYGON ((38.82519 8.83942, 38.82519 8.84841, ...</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geom_id  no2_mean                                           geometry  \\\n",
       "0        0  0.000051  POLYGON ((38.78925 8.83942, 38.78925 8.84841, ...   \n",
       "1        1  0.000033  POLYGON ((38.79824 8.83942, 38.79824 8.84841, ...   \n",
       "2        2  0.000033  POLYGON ((38.80722 8.83942, 38.80722 8.84841, ...   \n",
       "3        3  0.000033  POLYGON ((38.8162 8.83942, 38.8162 8.84841, 38...   \n",
       "4        4  0.000033  POLYGON ((38.82519 8.83942, 38.82519 8.84841, ...   \n",
       "\n",
       "        date  \n",
       "0 2023-01-01  \n",
       "1 2023-01-01  \n",
       "2 2023-01-01  \n",
       "3 2023-01-01  \n",
       "4 2023-01-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = load_mesh_series(ADDIS_FOLDER)\n",
    "print(\"Total rows:\", len(gdf))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0c12f",
   "metadata": {},
   "source": [
    "### Create autoregressive lags 1…14 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ab0f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298158, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_lag_features(gdf, nlags=14)\n",
    "# drop the first 14 days per cell (NaN lags)\n",
    "df = df.dropna(subset=[f\"no2_mean_lag{l}\" for l in range(1,15)])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04f16c",
   "metadata": {},
   "source": [
    "### Precompute spatial neighbors and add mean-lag features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0bd7be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (546) does not match length of index (298158)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# apply to each row-group: transform expects the full static+lags DataFrame per time slice\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# so merge geometry into df and then extract neighbor features\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      9\u001b[0m     df\u001b[38;5;241m.\u001b[39mmerge(static\u001b[38;5;241m.\u001b[39mreset_index(), on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m       \u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m neigh_feats \u001b[38;5;241m=\u001b[39m \u001b[43mneighborer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_merged\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# join back\u001b[39;00m\n\u001b[0;32m     14\u001b[0m df_full \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_merged\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), neigh_feats], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AirPollution_Analysis\\air-pollution-mobility-research-project\\src\\feature_engineering.py:60\u001b[0m, in \u001b[0;36mNeighborAggregator.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     58\u001b[0m     df_neigh \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[neigh]\n\u001b[0;32m     59\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend(df_neigh[lag_cols]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_prefix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneigh_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Luis.ParraMorales\\AppData\\Local\\miniforge3\\Lib\\site-packages\\pandas\\core\\frame.py:859\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m         dtype,\n\u001b[0;32m    858\u001b[0m     )\n\u001b[1;32m--> 859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    868\u001b[0m         data,\n\u001b[0;32m    869\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    873\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    874\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Luis.ParraMorales\\AppData\\Local\\miniforge3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Luis.ParraMorales\\AppData\\Local\\miniforge3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:630\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    627\u001b[0m         val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    629\u001b[0m     val \u001b[38;5;241m=\u001b[39m sanitize_array(val, index, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 630\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m     refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    633\u001b[0m homogenized\u001b[38;5;241m.\u001b[39mappend(val)\n",
      "File \u001b[1;32mc:\\Users\\Luis.ParraMorales\\AppData\\Local\\miniforge3\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (546) does not match length of index (298158)"
     ]
    }
   ],
   "source": [
    "# we only need one GeoDataFrame (static geometry & id)\n",
    "static = gdf.drop_duplicates([\"geom_id\"])[[\"geom_id\",\"geometry\"]].set_index(\"geom_id\")\n",
    "neighborer = NeighborAggregator(k=8, id_col=\"geom_id\")\n",
    "neighborer.fit(static.reset_index(), None)\n",
    "\n",
    "# apply to each row-group: transform expects the full static+lags DataFrame per time slice\n",
    "# so merge geometry into df and then extract neighbor features\n",
    "df_merged = (\n",
    "    df.merge(static.reset_index(), on=\"geom_id\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "neigh_feats = neighborer.transform(df_merged)\n",
    "# join back\n",
    "df_full = pd.concat([df_merged.reset_index(drop=True), neigh_feats], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7dc791",
   "metadata": {},
   "source": [
    "### Split into training (all 2023) vs test (last quarter 2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2930c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"year\"] = df_full[\"date\"].dt.year\n",
    "train = df_full[df_full[\"year\"] < 2024]\n",
    "test  = df_full[df_full[\"year\"] >= 2024]\n",
    "\n",
    "y_train = train[\"no2_mean\"]\n",
    "y_test  = test[\"no2_mean\"]\n",
    "X_train = train.drop(columns=[\"no2_mean\",\"geometry\",\"date\",\"year\"])\n",
    "X_test  = test.drop(columns=[\"no2_mean\",\"geometry\",\"date\",\"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5287dd67",
   "metadata": {},
   "source": [
    "### Random Forest with scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rf\", RandomForestRegressor(\n",
    "        n_estimators=300, \n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        oob_score=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"OOB R²:\", pipeline.named_steps[\"rf\"].oob_score_)\n",
    "print(\"Test R²:\", pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99863934",
   "metadata": {},
   "source": [
    "### Global feature importance (mean |SHAP|) and beeswarm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(pipeline.named_steps[\"rf\"])\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# bar plot\n",
    "shap.plots.bar(explainer, max_display=15)\n",
    "# beeswarm\n",
    "shap.summary_plot(shap_values, X_test, max_display=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347e0aa",
   "metadata": {},
   "source": [
    "### Dependence plot for top-2 features, and mapping one SHAP feature back to space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = X_test.columns[np.argsort(np.abs(shap_values).mean(0))[-2:]]\n",
    "for feat in top_feats:\n",
    "    shap.dependence_plot(feat, shap_values, X_test)\n",
    "\n",
    "# map per-cell mean SHAP of first feature\n",
    "mean_shap = pd.DataFrame({\n",
    "    \"geom_id\": test[\"geom_id\"],\n",
    "    \"shap1\": shap_values[:, X_test.columns.get_loc(top_feats[-1])]\n",
    "}).groupby(\"geom_id\").mean().reset_index()\n",
    "\n",
    "map_gdf = static.reset_index().merge(mean_shap, on=\"geom_id\")\n",
    "map_gdf.plot(column=\"shap1\", legend=True, cmap=\"plasma\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e986807",
   "metadata": {},
   "source": [
    "### Approximate elasticities from SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticities = []\n",
    "for feat in X_test.columns:\n",
    "    dx = X_test[feat].quantile(0.75) - X_test[feat].quantile(0.25)\n",
    "    r = (shap_values[:, X_test.columns.get_loc(feat)] / pipeline.predict(X_test)) \\\n",
    "        * (X_test[feat] / dx)\n",
    "    elasticities.append({\n",
    "        \"feature\": feat,\n",
    "        \"median\": np.median(r),\n",
    "        \"p10\": np.percentile(r,10),\n",
    "        \"p90\": np.percentile(r,90)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(elasticities).sort_values(\"median\", ascending=False).head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
